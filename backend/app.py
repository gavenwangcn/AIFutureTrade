# This must be at the very top of the file, before any other imports
import eventlet
eventlet.monkey_patch()

"""
Flask application for AI Futures Trading System
"""
from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import os
import time
import threading
import json
from datetime import datetime, timedelta, timezone
from trade.trading_engine import TradingEngine
from market.market_data import MarketDataFetcher
from trade.ai_trader import AITrader
from common.database_basic import Database
from common.database_account import AccountDatabase
from common.binance_futures import BinanceFuturesAccountClient
from common.version import __version__
from trade.prompt_defaults import DEFAULT_BUY_CONSTRAINTS, DEFAULT_SELL_CONSTRAINTS

import common.config as app_config
import logging
import sys

# ============ Application Initialization ============

app = Flask(__name__)
# CORSé…ç½®ï¼šå…è®¸å‰ç«¯æœåŠ¡è®¿é—®
# æ³¨æ„ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåº”è¯¥é™åˆ¶å…·ä½“çš„åŸŸåï¼Œè€Œä¸æ˜¯ä½¿ç”¨é€šé…ç¬¦
CORS(app, resources={
    r"/api/*": {
        "origins": "*",  # å…è®¸æ‰€æœ‰æ¥æºï¼ˆç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶ï¼‰
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],  # æ˜ç¡®æ”¯æŒæ‰€æœ‰HTTPæ–¹æ³•
        "allow_headers": ["Content-Type", "Authorization"],  # å…è®¸çš„è¯·æ±‚å¤´
        "expose_headers": ["Content-Type"],  # æš´éœ²çš„å“åº”å¤´
        "supports_credentials": False  # ä¸æ”¯æŒå‡­è¯
    },
    r"/socket.io/*": {"origins": "*"}  # å…è®¸æ‰€æœ‰æ¥æºï¼ˆç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶ï¼‰
})
# ä½¿ç”¨eventletä½œä¸ºå¼‚æ­¥æ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
# async_mode='eventlet' æä¾›æ›´å¥½çš„å¹¶å‘æ€§èƒ½
socketio = SocketIO(
    app, 
    cors_allowed_origins="*",  # Socket.IOå…è®¸æ‰€æœ‰æ¥æº
    async_mode='eventlet',  # ä½¿ç”¨eventletå¼‚æ­¥æ¨¡å¼
    logger=False,  # ç¦ç”¨SocketIOæ—¥å¿—ä»¥å‡å°‘å¼€é”€
    engineio_logger=False,  # ç¦ç”¨EngineIOæ—¥å¿—
    ping_timeout=60,  # WebSocket pingè¶…æ—¶æ—¶é—´
    ping_interval=25,  # WebSocket pingé—´éš”
    max_http_buffer_size=1e6,  # æœ€å¤§HTTPç¼“å†²åŒºå¤§å°
    allow_upgrades=True,  # å…è®¸åè®®å‡çº§
    transports=['websocket', 'polling']  # æ”¯æŒçš„ä¼ è¾“æ–¹å¼
)

# ============ Logging Configuration ============

def get_log_level():
    """ä»é…ç½®è·å–æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤ä¸º INFO"""
    log_level_str = getattr(app_config, 'LOG_LEVEL', 'INFO').upper()
    log_level_map = {
        'DEBUG': logging.DEBUG,
        'INFO': logging.INFO,
        'WARNING': logging.WARNING,
        'ERROR': logging.ERROR,
        'CRITICAL': logging.CRITICAL
    }
    return log_level_map.get(log_level_str, logging.INFO)

log_format = getattr(app_config, 'LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
log_date_format = getattr(app_config, 'LOG_DATE_FORMAT', '%Y-%m-%d %H:%M:%S')

logging.basicConfig(
    level=get_log_level(),
    format=log_format,
    datefmt=log_date_format,
    handlers=[logging.StreamHandler(sys.stdout)]
)

logging.getLogger('werkzeug').setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# ============ Global Configuration ============

# Database initialization (using MySQL configuration from app_config)
db = Database()

# Initialize database tables immediately when the application starts
# This ensures tables are created even when running with gunicorn or other WSGI servers
with app.app_context():
    db.init_db()
    logger.info("Database tables initialized")

# åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–åå°æœåŠ¡ï¼ˆå·²ç§»é™¤MySQLæ¶¨è·Œå¹…æ¦œåŒæ­¥æœåŠ¡ï¼‰
def _init_background_services():
    """åˆå§‹åŒ–åå°æœåŠ¡ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
    logger.info("ğŸš€ åˆå§‹åŒ–åå°æœåŠ¡...")
    logger.info("âœ… åå°æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆæ¶¨è·Œæ¦œæ•°æ®ç›´æ¥ä»24_market_tickersè¡¨æŸ¥è¯¢ï¼Œæ— éœ€å¼‚æ­¥åŒæ­¥ï¼‰")

market_fetcher = MarketDataFetcher(db)
trading_engines = {}
auto_trading = getattr(app_config, 'AUTO_TRADING', True)
TRADE_FEE_RATE = getattr(app_config, 'TRADE_FEE_RATE', 0.001)
LEADERBOARD_REFRESH_INTERVAL = getattr(app_config, 'FUTURES_LEADERBOARD_REFRESH', 10)

leaderboard_thread = None
leaderboard_stop_event = threading.Event()

# ============ Helper Functions ============

def init_trading_engine_for_model(model_id: int):
    """Initialize trading engine for a model if possible."""
    logger.info(f"Initializing trading engine for model {model_id}...")
    
    model = db.get_model(model_id)
    if not model:
        logger.warning(f"Model {model_id} not found, cannot initialize trading engine")
        return None, 'Model not found'

    provider = db.get_provider(model['provider_id'])
    if not provider:
        logger.warning(f"Provider not found for model {model_id}, cannot initialize trading engine")
        return None, 'Provider not found'

    logger.info(f"Creating AITrader instance for model {model_id} with provider {provider.get('provider_type', 'openai')} and model {model['model_name']}")
    
    trading_engines[model_id] = TradingEngine(
        model_id=model_id,
        db=db,
        market_fetcher=market_fetcher,
        ai_trader=AITrader(
            provider_type=provider.get('provider_type', 'openai'),
            api_key=provider['api_key'],
            api_url=provider['api_url'],
            model_name=model['model_name']
        ),
        trade_fee_rate=TRADE_FEE_RATE
    )
    
    logger.info(f"Successfully initialized trading engine for model {model_id}")
    return trading_engines[model_id], None

def get_tracked_symbols():
    """Get list of tracked future symbols"""
    symbols = db.get_future_symbols()
    if not symbols:
        logger.warning('No futures configured. Please add futures via /api/futures.')
    return symbols

def get_trading_interval_seconds() -> int:
    """Read trading frequency from settings (minutes) and return seconds."""
    default_interval_seconds = getattr(app_config, 'TRADING_INTERVAL', 3600)
    default_minutes = max(1, int(default_interval_seconds / 60))
    try:
        settings = db.get_settings()
        minutes = int(settings.get('trading_frequency_minutes', default_minutes))
    except Exception as e:
        logger.warning(f"Unable to load trading frequency setting: {e}")
        minutes = default_minutes

    minutes = max(1, min(1440, minutes))
    return minutes * 60

def init_trading_engines():
    """Initialize trading engines for all models"""
    try:
        models = db.get_all_models()

        if not models:
            logger.warning("No trading models found")
            return

        logger.info(f"\nINIT: Initializing trading engines...")
        for model in models:
            model_id = model['id']
            model_name = model['name']

            try:
                provider = db.get_provider(model['provider_id'])
                if not provider:
                    logger.warning(f"  Model {model_id} ({model_name}): Provider not found")
                    continue

                trading_engines[model_id] = TradingEngine(
                    model_id=model_id,
                    db=db,
                    market_fetcher=market_fetcher,
                    ai_trader=AITrader(
                    provider_type=provider.get('provider_type', 'openai'),
                    api_key=provider['api_key'],
                    api_url=provider['api_url'],
                    model_name=model['model_name']
                ),
                    trade_fee_rate=TRADE_FEE_RATE
                )
                logger.info(f"  OK: Model {model_id} ({model_name})")
            except Exception as e:
                logger.error(f"  Model {model_id} ({model_name}): {e}")
                continue

        logger.info(f"Initialized {len(trading_engines)} engine(s)\n")

    except Exception as e:
        logger.error(f"Init engines failed: {e}\n")

# ============ Background Tasks ============

def _leaderboard_loop():
    """
    åå°å¾ªç¯ä»»åŠ¡ï¼šå®šæœŸåŒæ­¥æ¶¨è·Œå¹…æ¦œæ•°æ®åˆ°ClickHouseï¼ˆä¸å†é€šè¿‡WebSocketæ¨é€åˆ°å‰ç«¯ï¼‰
    
    æµç¨‹ï¼š
    1. å¯åŠ¨å¾ªç¯ï¼Œè®°å½•å¯åŠ¨ä¿¡æ¯
    2. å®šæœŸè°ƒç”¨ sync_leaderboard åŒæ­¥æ•°æ®åˆ°ClickHouse
    3. ä¸å†é€šè¿‡ WebSocket æ¨é€åˆ°å‰ç«¯ï¼ˆå‰ç«¯æ”¹ä¸ºè½®è¯¢æ–¹å¼è·å–æ•°æ®ï¼‰
    4. ç­‰å¾…æŒ‡å®šé—´éš”åç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
    5. æ”¶åˆ°åœæ­¢ä¿¡å·æ—¶é€€å‡ºå¾ªç¯
    
    æ³¨æ„ï¼šå‰ç«¯å·²æ”¹ä¸ºè½®è¯¢æ–¹å¼è·å–æ•°æ®ï¼Œä¸å†ä½¿ç”¨WebSocketæ¨é€
    """
    thread_id = threading.current_thread().ident
    logger.info(f"[Leaderboard Worker-{thread_id}] æ¶¨è·Œå¹…æ¦œåŒæ­¥å¾ªç¯å¯åŠ¨ï¼Œåˆ·æ–°é—´éš”: {LEADERBOARD_REFRESH_INTERVAL} ç§’ï¼ˆä»…åŒæ­¥åˆ°ClickHouseï¼Œä¸æ¨é€å‰ç«¯ï¼‰")
    
    wait_seconds = max(5, LEADERBOARD_REFRESH_INTERVAL)
    cycle_count = 0
    
    while not leaderboard_stop_event.is_set():
        cycle_count += 1
        cycle_start_time = datetime.now(timezone(timedelta(hours=8)))
        
        try:
            # è°ƒç”¨åŒæ­¥æ–¹æ³•ï¼ˆä¸å¼ºåˆ¶åˆ·æ–°ï¼Œä½¿ç”¨ç¼“å­˜æœºåˆ¶ï¼‰
            # ä»…åŒæ­¥æ•°æ®åˆ°ClickHouseï¼Œä¸å†é€šè¿‡WebSocketæ¨é€
            data = market_fetcher.sync_leaderboard(force=False)
            
            # æ£€æŸ¥åŒæ­¥ç»“æœï¼ˆä»…è®°å½•æ—¥å¿—ï¼Œä¸æ¨é€ï¼‰
            if data:
                gainers_count = len(data.get('gainers', [])) if data.get('gainers') else 0
                losers_count = len(data.get('losers', [])) if data.get('losers') else 0
                logger.debug(
                    f"[Leaderboard Worker-{thread_id}] [å¾ªç¯ #{cycle_count}] åŒæ­¥å®Œæˆ: "
                    f"æ¶¨å¹…æ¦œ {gainers_count} æ¡, è·Œå¹…æ¦œ {losers_count} æ¡ "
                    f"ï¼ˆå·²åŒæ­¥åˆ°ClickHouseï¼Œå‰ç«¯é€šè¿‡è½®è¯¢è·å–ï¼‰"
                )
            else:
                logger.warning(f"[Leaderboard Worker-{thread_id}] [å¾ªç¯ #{cycle_count}] åŒæ­¥è¿”å›ç©ºæ•°æ®")
                
        except Exception as exc:
            cycle_duration = (datetime.now(timezone(timedelta(hours=8))) - cycle_start_time).total_seconds()
            logger.error(f"[Leaderboard Worker-{thread_id}] [å¾ªç¯ #{cycle_count}] æ¶¨è·Œå¹…æ¦œåŒæ­¥å¤±è´¥: {exc}, è€—æ—¶: {cycle_duration:.2f} ç§’")
            import traceback
            logger.error(f"[Leaderboard Worker-{thread_id}] [å¾ªç¯ #{cycle_count}] é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
        
        # ç­‰å¾…æŒ‡å®šé—´éš”ï¼ˆå¯è¢«åœæ­¢äº‹ä»¶ä¸­æ–­ï¼‰
        leaderboard_stop_event.wait(wait_seconds)
    
    logger.info(f"[Leaderboard Worker-{thread_id}] æ¶¨è·Œå¹…æ¦œåŒæ­¥å¾ªç¯åœæ­¢ï¼Œæ€»å¾ªç¯æ¬¡æ•°: {cycle_count}")


def start_leaderboard_worker():
    """Start background worker for leaderboard updates"""
    global leaderboard_thread
    if leaderboard_thread and leaderboard_thread.is_alive():
        return
    leaderboard_stop_event.clear()
    leaderboard_thread = threading.Thread(target=_leaderboard_loop, daemon=True)
    leaderboard_thread.start()

def trading_loop():
    """Main trading loop for automatic trading"""
    logger.info("Trading loop started")

    while auto_trading:
        try:
            if not trading_engines:
                time.sleep(10)
                continue

            logger.info(f"\n{'='*60}")
            logger.info(f"CYCLE: {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info(f"Active models: {len(trading_engines)}")
            logger.info(f"{'='*60}")

            for model_id, engine in list(trading_engines.items()):
                try:
                    if not db.is_model_auto_trading_enabled(model_id):
                        logger.info(f"SKIP: Model {model_id} auto trading paused")
                        continue

                    logger.info(f"\nEXEC: Model {model_id}")
                    result = engine.execute_trading_cycle()

                    if result.get('success'):
                        logger.info(f"OK: Model {model_id} completed")
                        if result.get('executions'):
                            for exec_result in result['executions']:
                                signal = exec_result.get('signal', 'unknown')
                                symbol = exec_result.get('future', exec_result.get('symbol', 'unknown'))
                                msg = exec_result.get('message', '')
                                if signal != 'hold':
                                    logger.info(f"  TRADE: {symbol}: {msg}")
                    else:
                        error = result.get('error', 'Unknown error')
                        logger.warning(f"Model {model_id} failed: {error}")

                except Exception as e:
                    logger.error(f"Model {model_id} exception: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                    continue

            interval_seconds = get_trading_interval_seconds()
            interval_minutes = interval_seconds / 60
            logger.info(f"\n{'='*60}")
            logger.info(f"SLEEP: Waiting {interval_minutes:.1f} minute(s) for next cycle")
            logger.info(f"{'='*60}\n")

            time.sleep(interval_seconds)

        except Exception as e:
            logger.critical(f"\nTrading loop error: {e}")
            import traceback
            logger.critical(traceback.format_exc())
            logger.info("RETRY: Retrying in 60 seconds\n")
            time.sleep(60)

    logger.info("Trading loop stopped")

# ============ Page Routes ============

# åå°æœåŠ¡åˆå§‹åŒ–æ ‡å¿—ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œç¡®ä¿æ‰€æœ‰å‡½æ•°éƒ½å·²å®šä¹‰ï¼‰
_background_services_initialized = False

@app.before_request
def _ensure_background_services():
    """ç¡®ä¿åå°æœåŠ¡å·²å¯åŠ¨ï¼ˆåœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æ—¶è°ƒç”¨ï¼‰"""
    global _background_services_initialized
    if not _background_services_initialized:
        _init_background_services()
        _background_services_initialized = True

@app.after_request
def after_request(response):
    """æ·»åŠ  CORS å“åº”å¤´ï¼Œç¡®ä¿æ‰€æœ‰è¯·æ±‚éƒ½èƒ½æ­£ç¡®å¤„ç†"""
    # å¯¹äºæ‰€æœ‰ API è¯·æ±‚ï¼Œæ·»åŠ  CORS å¤´
    if request.path.startswith('/api/'):
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type, Authorization')
        response.headers.add('Access-Control-Max-Age', '3600')
    return response

@app.route('/')
def index():
    """Main page route - è¿”å›ç®€å•çš„çŠ¶æ€ä¿¡æ¯ï¼Œä¸æ¸²æŸ“æ¨¡æ¿"""
    return jsonify({
        'status': 'running',
        'message': 'AI Future Trade Backend API',
        'version': __version__,
        'frontend_url': 'http://localhost:3000',
        'api_endpoint': '/api/'
    })


# ============ Provider API Endpoints ============
# APIæä¾›æ–¹ç®¡ç†ï¼šç”¨äºé…ç½®å’Œç®¡ç†AIæ¨¡å‹æä¾›æ–¹ï¼ˆå¦‚OpenAIã€DeepSeekç­‰ï¼‰

@app.route('/api/providers', methods=['GET'])
def get_providers():
    """
    è·å–æ‰€æœ‰APIæä¾›æ–¹åˆ—è¡¨
    
    Returns:
        JSON: æä¾›æ–¹åˆ—è¡¨ï¼ŒåŒ…å«idã€nameã€api_urlã€api_keyç­‰ä¿¡æ¯
    """
    providers = db.get_all_providers()
    return jsonify(providers)

@app.route('/api/providers', methods=['POST'])
def add_provider():
    """
    æ·»åŠ æ–°çš„APIæä¾›æ–¹
    
    Request Body:
        name (str): æä¾›æ–¹åç§°
        api_url (str): APIåœ°å€
        api_key (str): APIå¯†é’¥
        models (str, optional): æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
        provider_type (str, optional): æä¾›æ–¹ç±»å‹ï¼Œé»˜è®¤'openai'
    
    Returns:
        JSON: åŒ…å«æ–°åˆ›å»ºçš„æä¾›æ–¹IDå’ŒæˆåŠŸæ¶ˆæ¯
    """
    data = request.json
    try:
        provider_id = db.add_provider(
            name=data['name'],
            api_url=data['api_url'],
            api_key=data['api_key'],
            models=data.get('models', ''),
            provider_type=data.get('provider_type', 'openai')
        )
        return jsonify({'id': provider_id, 'message': 'Provider added successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/providers/<int:provider_id>', methods=['DELETE', 'OPTIONS'])
def delete_provider(provider_id):
    """
    åˆ é™¤APIæä¾›æ–¹
    
    Args:
        provider_id (int): æä¾›æ–¹ID
    
    Returns:
        JSON: åˆ é™¤æ“ä½œç»“æœ
    """
    # å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Methods', 'DELETE, OPTIONS')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        return response
    
    try:
        db.delete_provider(provider_id)
        logger.info(f"Provider {provider_id} deleted successfully")
        return jsonify({'success': True, 'message': 'Provider deleted successfully'})
    except Exception as e:
        logger.error(f"Failed to delete provider {provider_id}: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/providers/models', methods=['POST'])
def fetch_provider_models():
    """
    ä»æä¾›æ–¹APIè·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    
    Request Body:
        api_url (str): APIåœ°å€
        api_key (str): APIå¯†é’¥
    
    Returns:
        JSON: åŒ…å«å¯ç”¨æ¨¡å‹åˆ—è¡¨
    """
    data = request.json
    api_url = data.get('api_url')
    api_key = data.get('api_key')

    if not api_url or not api_key:
        return jsonify({'error': 'API URL and key are required'}), 400

    try:
        models = []

        # æ ¹æ®æä¾›æ–¹ç±»å‹è°ƒç”¨ç›¸åº”çš„API
        if 'openai.com' in api_url.lower():
            import requests
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            response = requests.get(f'{api_url}/models', headers=headers, timeout=10)
            if response.status_code == 200:
                result = response.json()
                models = [m['id'] for m in result.get('data', []) if 'gpt' in m['id'].lower()]
        elif 'deepseek' in api_url.lower():
            import requests
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            response = requests.get(f'{api_url}/models', headers=headers, timeout=10)
            if response.status_code == 200:
                result = response.json()
                models = [m['id'] for m in result.get('data', [])]
        else:
            # é»˜è®¤è¿”å›å¸¸ç”¨æ¨¡å‹åç§°
            models = ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo']

        return jsonify({'models': models})
    except Exception as e:
        logger.error(f"Fetch models failed: {e}")
        return jsonify({'error': f'Failed to fetch models: {str(e)}'}), 500

# ============ Futures Configuration API Endpoints ============
# åˆçº¦é…ç½®ç®¡ç†ï¼šç”¨äºé…ç½®å’Œç®¡ç†äº¤æ˜“åˆçº¦ä¿¡æ¯ï¼ˆå¦‚BTCUSDTã€ETHUSDTç­‰ï¼‰

@app.route('/api/futures', methods=['GET'])
def list_futures():
    """
    è·å–æ‰€æœ‰åˆçº¦é…ç½®åˆ—è¡¨
    
    Returns:
        JSON: åˆçº¦é…ç½®åˆ—è¡¨ï¼ŒåŒ…å«symbolã€contract_symbolã€nameç­‰ä¿¡æ¯
    """
    try:
        futures = db.get_futures()
        return jsonify(futures)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/futures', methods=['POST'])
def add_future_config():
    """
    æ·»åŠ æ–°çš„åˆçº¦é…ç½®
    
    Request Body:
        symbol (str): äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚BTCï¼‰
        contract_symbol (str): åˆçº¦ç¬¦å·ï¼ˆå¦‚BTCUSDTï¼‰
        name (str): åˆçº¦åç§°ï¼ˆå¦‚æ¯”ç‰¹å¸æ°¸ç»­åˆçº¦ï¼‰
        exchange (str, optional): äº¤æ˜“æ‰€ï¼Œé»˜è®¤'BINANCE_FUTURES'
        link (str, optional): ç›¸å…³é“¾æ¥
        sort_order (int, optional): æ’åºé¡ºåºï¼Œé»˜è®¤0
    
    Returns:
        JSON: åŒ…å«æ–°åˆ›å»ºçš„åˆçº¦IDå’ŒæˆåŠŸæ¶ˆæ¯
    """
    data = request.json or {}
    symbol = data.get('symbol', '').strip().upper()
    contract_symbol = data.get('contract_symbol', '').strip().upper()
    name = data.get('name', '').strip()
    exchange = data.get('exchange', 'BINANCE_FUTURES').strip().upper()
    link = (data.get('link') or '').strip()
    sort_order = data.get('sort_order')

    if not all([symbol, contract_symbol, name]):
        return jsonify({'error': 'symbol, contract_symbol, name are required'}), 400

    try:
        sort_order = int(sort_order)
    except (TypeError, ValueError):
        sort_order = 0

    try:
        future_id = db.add_future(
            symbol=symbol,
            contract_symbol=contract_symbol,
            name=name,
            exchange=exchange,
            link=link or None,
            sort_order=sort_order
        )
        return jsonify({'id': future_id, 'message': 'Future added successfully'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/futures/<int:future_id>', methods=['DELETE', 'OPTIONS'])
def delete_future_config(future_id):
    """
    åˆ é™¤åˆçº¦é…ç½®
    
    Args:
        future_id (int): åˆçº¦ID
    
    Returns:
        JSON: åˆ é™¤æ“ä½œç»“æœ
    """
    # å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Methods', 'DELETE, OPTIONS')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        return response
    
    try:
        db.delete_future(future_id)
        logger.info(f"Future {future_id} deleted successfully")
        return jsonify({'success': True, 'message': 'Future deleted successfully'})
    except Exception as e:
        logger.error(f"Failed to delete future {future_id}: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500

# ============ Model API Endpoints ============
# äº¤æ˜“æ¨¡å‹ç®¡ç†ï¼šç”¨äºåˆ›å»ºã€é…ç½®å’Œç®¡ç†AIäº¤æ˜“æ¨¡å‹

@app.route('/api/models', methods=['GET'])
def get_models():
    """
    è·å–æ‰€æœ‰äº¤æ˜“æ¨¡å‹åˆ—è¡¨
    
    Returns:
        JSON: æ¨¡å‹åˆ—è¡¨ï¼ŒåŒ…å«idã€nameã€provider_idã€model_nameç­‰ä¿¡æ¯
    """
    models = db.get_all_models()
    return jsonify(models)

@app.route('/api/models/<int:model_id>', methods=['GET'])
def get_model_by_id(model_id):
    """Get a single model by ID"""
    try:
        model = db.get_model(model_id)
        if not model:
            return jsonify({'error': 'Model not found'}), 404
        return jsonify(model)
    except Exception as e:
        logger.error(f"Failed to get model {model_id}: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/models', methods=['POST'])
def add_model():
    """
    Add new trading model
    
    ã€symbol_sourceå‚æ•°è¯´æ˜ã€‘
    å‰ç«¯ä¼ é€’çš„symbol_sourceå­—æ®µç”¨äºæŒ‡å®šAIäº¤æ˜“ä¹°å…¥å†³ç­–æ—¶çš„äº¤æ˜“å¯¹æ•°æ®æºï¼š
    - 'leaderboard'ï¼ˆé»˜è®¤ï¼‰ï¼šä»æ¶¨è·Œæ¦œè·å–äº¤æ˜“å¯¹ï¼Œé€‚ç”¨äºå…³æ³¨å¸‚åœºçƒ­ç‚¹çš„ç­–ç•¥
    - 'future'ï¼šä»futuresè¡¨è·å–æ‰€æœ‰å·²é…ç½®çš„äº¤æ˜“å¯¹ï¼Œé€‚ç”¨äºå…¨å¸‚åœºæ‰«æç­–ç•¥
    
    è¯¥å‚æ•°ä»…å½±å“buyç±»å‹çš„AIäº¤äº’ï¼Œsellé€»è¾‘ä¸å—å½±å“ã€‚
    ç›¸å…³è°ƒç”¨ï¼štrading_engine._select_buy_candidates() ä¼šæ ¹æ®æ­¤å€¼é€‰æ‹©ä¸åŒçš„æ•°æ®æº
    """
    data = request.json or {}
    try:
        provider = db.get_provider(data['provider_id'])
        if not provider:
            return jsonify({'error': 'Provider not found'}), 404

        # è·å–account_aliaså’Œis_virtualå‚æ•°
        account_alias = data.get('account_alias', '').strip()
        is_virtual = data.get('is_virtual', True)  # é»˜è®¤å€¼ä¸º Trueï¼ˆè™šæ‹Ÿè´¦æˆ·ï¼‰
        
        # éªŒè¯account_aliaså¿…å¡«
        if not account_alias:
            return jsonify({'error': 'account_alias is required'}), 400
        
        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šå¦‚æœæ²¡æœ‰account_aliasï¼Œåˆ™ä½¿ç”¨api_keyå’Œapi_secret
        api_key = data.get('api_key', '').strip()
        api_secret = data.get('api_secret', '').strip()
        
        # è·å–max_positionså‚æ•°ï¼Œé»˜è®¤å€¼ä¸º3
        max_positions = int(data.get('max_positions', 3))
        if max_positions < 1:
            return jsonify({'error': 'max_positions must be >= 1'}), 400
        
        model_id = db.add_model(
            name=data['name'],
            provider_id=data['provider_id'],
            model_name=data['model_name'],
            initial_capital=float(data.get('initial_capital', 100000)),
            leverage=int(data.get('leverage', 10)),
            api_key=api_key,
            api_secret=api_secret,
            account_alias=account_alias,
            is_virtual=bool(is_virtual),
            symbol_source=data.get('symbol_source', 'leaderboard'),  # ã€æ–°å¢å‚æ•°ã€‘äº¤æ˜“å¯¹æ•°æ®æºï¼Œé»˜è®¤'leaderboard'ä¿æŒå‘åå…¼å®¹
            max_positions=max_positions  # ã€æ–°å¢å‚æ•°ã€‘æœ€å¤§æŒä»“æ•°é‡ï¼Œé»˜è®¤3
        )

        model = db.get_model(model_id)
        provider = db.get_provider(model['provider_id'])
        if not provider:
            return jsonify({'error': 'Provider not found'}), 404

        trading_engines[model_id] = TradingEngine(
            model_id=model_id,
            db=db,
            market_fetcher=market_fetcher,
            ai_trader=AITrader(
                provider_type=provider['provider_type'],
                api_key=provider['api_key'],
                api_url=provider['api_url'],
                model_name=model['model_name']
            ),
            trade_fee_rate=TRADE_FEE_RATE
        )
        logger.info(f"Model {model_id} ({data['name']}) initialized")
        
        # åˆå§‹åŒ–æ¨¡å‹çš„é»˜è®¤promptsï¼ˆä»prompt_defaults.pyè¯»å–ï¼‰
        try:
            from trade.prompt_defaults import DEFAULT_BUY_CONSTRAINTS, DEFAULT_SELL_CONSTRAINTS
            db.upsert_model_prompt(
                model_id=model_id,
                buy_prompt=DEFAULT_BUY_CONSTRAINTS,
                sell_prompt=DEFAULT_SELL_CONSTRAINTS
            )
            logger.info(f"Model {model_id} default prompts initialized")
        except Exception as prompt_err:
            logger.warning(f"Failed to initialize default prompts for model {model_id}: {prompt_err}")
            # ä¸é˜»æ­¢æ¨¡å‹åˆ›å»ºï¼Œpromptsåˆå§‹åŒ–å¤±è´¥ä¸å½±å“æ¨¡å‹åˆ›å»º

        return jsonify({'id': model_id, 'message': 'Model added successfully'})

    except Exception as e:
        logger.error(f"Failed to add model: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/models/<int:model_id>', methods=['DELETE', 'OPTIONS'])
def delete_model(model_id):
    """
    åˆ é™¤äº¤æ˜“æ¨¡å‹
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Returns:
        JSON: åˆ é™¤æ“ä½œç»“æœ
    """
    # å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Methods', 'DELETE, OPTIONS')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        return response
    
    try:
        model = db.get_model(model_id)
        model_name = model['name'] if model else f"ID-{model_id}"

        db.delete_model(model_id)
        if model_id in trading_engines:
            del trading_engines[model_id]

        logger.info(f"Model {model_id} ({model_name}) deleted")
        return jsonify({'success': True, 'message': 'Model deleted successfully'})
    except Exception as e:
        logger.error(f"Delete model {model_id} failed: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/models/<int:model_id>/portfolio', methods=['GET'])
def get_portfolio(model_id):
    """
    è·å–æ¨¡å‹çš„æŠ•èµ„ç»„åˆæ•°æ®
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Returns:
        JSON: åŒ…å«æŠ•èµ„ç»„åˆã€è´¦æˆ·ä»·å€¼å†å²ã€è‡ªåŠ¨äº¤æ˜“çŠ¶æ€ç­‰ä¿¡æ¯
    """
    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': f'Model {model_id} not found'}), 404

    symbols = get_tracked_symbols()
    prices_data = market_fetcher.get_prices(symbols)
    current_prices = {symbol: data['price'] for symbol, data in prices_data.items()}

    try:
        portfolio = db.get_portfolio(model_id, current_prices)
    except ValueError as exc:
        return jsonify({'error': str(exc)}), 404

    account_value = db.get_account_value_history(model_id, limit=100)

    return jsonify({
        'portfolio': portfolio,
        'account_value_history': account_value,
        'auto_trading_enabled': bool(model.get('auto_trading_enabled', 1)),
        'leverage': model.get('leverage', 10)
    })

@app.route('/api/models/<int:model_id>/portfolio/symbols', methods=['GET'])
def get_model_portfolio_symbols(model_id):
    """
    è·å–æ¨¡å‹çš„æŒä»“åˆçº¦symbolåˆ—è¡¨åŠå…¶å®æ—¶ä»·æ ¼å’Œå½“æ—¥æˆäº¤é¢ç­‰å¸‚åœºæ•°æ®
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Returns:
        JSON: åŒ…å«symbolåˆ—è¡¨åŠå…¶å®æ—¶ä»·æ ¼ã€å½“æ—¥æˆäº¤é¢ã€æ¶¨è·Œç™¾åˆ†æ¯”ç­‰å¸‚åœºæ•°æ®
    """
    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': f'Model {model_id} not found'}), 404
    
    from common.database_mysql import MySQLDatabase
    mysql_db = MySQLDatabase(auto_init_tables=False)
    
    # è·å–æ¨¡å‹æŒæœ‰symbolsåˆ—è¡¨
    symbols = mysql_db.get_model_portfolio_symbols(model_id)
    
    if not symbols:
        return jsonify({'data': []}), 200
    
    # è·å–å®æ—¶ä»·æ ¼æ•°æ®
    prices_data = market_fetcher.get_prices(symbols)
    
    # æ„å»ºå“åº”æ•°æ®
    result = []
    for symbol in symbols:
        symbol_data = {
            'symbol': symbol,
            'price': prices_data.get(symbol, {}).get('price', 0),
            'change': prices_data.get(symbol, {}).get('change', 0),
            'changePercent': prices_data.get(symbol, {}).get('changePercent', 0),
            'volume': prices_data.get(symbol, {}).get('volume', 0),
            'quoteVolume': prices_data.get(symbol, {}).get('quoteVolume', 0),
            'high': prices_data.get(symbol, {}).get('high', 0),
            'low': prices_data.get(symbol, {}).get('low', 0)
        }
        result.append(symbol_data)
    
    return jsonify({'data': result}), 200

@app.route('/api/models/<int:model_id>/trades', methods=['GET'])
def get_trades(model_id):
    """
    è·å–æ¨¡å‹çš„äº¤æ˜“å†å²è®°å½•
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Query Parameters:
        limit (int, optional): è¿”å›è®°å½•æ•°é™åˆ¶ï¼Œé»˜è®¤50
    
    Returns:
        JSON: äº¤æ˜“è®°å½•åˆ—è¡¨
    """
    limit = request.args.get('limit', 50, type=int)
    trades = db.get_trades(model_id, limit=limit)
    return jsonify(trades)

@app.route('/api/models/<int:model_id>/conversations', methods=['GET'])
def get_conversations(model_id):
    """
    è·å–æ¨¡å‹çš„å¯¹è¯å†å²è®°å½•
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Query Parameters:
        limit (int, optional): è¿”å›è®°å½•æ•°é™åˆ¶ï¼Œé»˜è®¤20
    
    Returns:
        JSON: å¯¹è¯è®°å½•åˆ—è¡¨
    """
    limit = request.args.get('limit', 20, type=int)
    conversations = db.get_conversations(model_id, limit=limit)
    return jsonify(conversations)

@app.route('/api/models/<int:model_id>/prompts', methods=['GET'])
def get_model_prompts(model_id):
    """
    è·å–æ¨¡å‹çš„æç¤ºè¯é…ç½®ï¼ˆä¹°å…¥å’Œå–å‡ºç­–ç•¥ï¼‰
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Returns:
        JSON: åŒ…å«ä¹°å…¥å’Œå–å‡ºæç¤ºè¯é…ç½®
    """
    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': 'Model not found'}), 404

    prompt_config = db.get_model_prompt(model_id) or {}
    buy_prompt = prompt_config.get('buy_prompt') or DEFAULT_BUY_CONSTRAINTS
    sell_prompt = prompt_config.get('sell_prompt') or DEFAULT_SELL_CONSTRAINTS

    return jsonify({
        'model_id': model_id,
        'model_name': model.get('name'),
        'buy_prompt': buy_prompt,
        'sell_prompt': sell_prompt,
        'has_custom': bool(prompt_config),
        'updated_at': prompt_config.get('updated_at') if prompt_config else None
    })

@app.route('/api/models/<int:model_id>/prompts', methods=['PUT'])
def update_model_prompts(model_id):
    """
    æ›´æ–°æ¨¡å‹çš„æç¤ºè¯é…ç½®
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Request Body:
        buy_prompt (str, optional): ä¹°å…¥ç­–ç•¥æç¤ºè¯
        sell_prompt (str, optional): å–å‡ºç­–ç•¥æç¤ºè¯
    
    Returns:
        JSON: æ›´æ–°æ“ä½œç»“æœ
    """
    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': 'Model not found'}), 404

    data = request.json or {}
    buy_prompt = data.get('buy_prompt')
    sell_prompt = data.get('sell_prompt')

    success = db.upsert_model_prompt(model_id, buy_prompt, sell_prompt)
    if not success:
        return jsonify({'error': 'Failed to update prompts'}), 500

    return jsonify({'success': True, 'message': 'Prompts updated successfully'})

@app.route('/api/models/<int:model_id>/max_positions', methods=['POST'])
def update_model_max_positions(model_id):
    """
    æ›´æ–°æ¨¡å‹çš„æœ€å¤§æŒä»“æ•°é‡
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Request Body:
        max_positions (int): æœ€å¤§æŒä»“æ•°é‡ï¼Œå¿…é¡» >= 1
    
    Returns:
        JSON: æ›´æ–°ç»“æœ
    """
    try:
        data = request.get_json()
        if not data or 'max_positions' not in data:
            return jsonify({'error': 'max_positions is required'}), 400
        
        max_positions = data.get('max_positions')
        if not isinstance(max_positions, int) or max_positions < 1:
            return jsonify({'error': 'max_positions must be an integer >= 1'}), 400
        
        if not db.set_model_max_positions(model_id, max_positions):
            return jsonify({'error': 'Failed to update max_positions'}), 500
        
        return jsonify({'success': True, 'max_positions': max_positions})
    except Exception as e:
        logger.error(f"Failed to update max_positions for model {model_id}: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/models/<int:model_id>/leverage', methods=['POST'])
def update_model_leverage(model_id):
    """
    æ›´æ–°æ¨¡å‹çš„æ æ†å€æ•°
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Request Body:
        leverage (int): æ æ†å€æ•°ï¼ˆå¿…é¡»å¤§äº0ï¼‰
    
    Returns:
        JSON: æ›´æ–°åçš„æ æ†å€æ•°
    """
    data = request.json or {}
    if 'leverage' not in data:
        return jsonify({'error': 'leverage is required'}), 400

    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': 'Model not found'}), 404

    leverage = int(data.get('leverage', 0))
    leverage = max(0, leverage)
    if not db.set_model_leverage(model_id, leverage):
        return jsonify({'error': 'Failed to update leverage'}), 500

    return jsonify({'model_id': model_id, 'leverage': leverage})

@app.route('/api/models/<int:model_id>/execute', methods=['POST'])
def execute_trading(model_id):
    """
    æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡äº¤æ˜“å‘¨æœŸï¼ˆç”¨äºæµ‹è¯•æˆ–æ‰‹åŠ¨è§¦å‘äº¤æ˜“ï¼‰
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Returns:
        JSON: äº¤æ˜“æ‰§è¡Œç»“æœï¼ŒåŒ…å«æˆåŠŸçŠ¶æ€å’Œæ‰§è¡Œè¯¦æƒ…
    
    Note:
        æ‰‹åŠ¨æ‰§è¡Œä¼šè‡ªåŠ¨å¯ç”¨è¯¥æ¨¡å‹çš„è‡ªåŠ¨äº¤æ˜“åŠŸèƒ½
    """
    if model_id not in trading_engines:
        engine, error = init_trading_engine_for_model(model_id)
        if error:
            return jsonify({'error': error}), 404
    else:
        engine = trading_engines[model_id]

    # Manual execution enables auto trading
    db.set_model_auto_trading(model_id, True)

    try:
        result = engine.execute_trading_cycle()
        result['auto_trading_enabled'] = True
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/models/<int:model_id>/auto-trading', methods=['POST'])
def set_model_auto_trading(model_id):
    """
    å¯ç”¨æˆ–ç¦ç”¨æ¨¡å‹çš„è‡ªåŠ¨äº¤æ˜“åŠŸèƒ½
    
    Args:
        model_id (int): æ¨¡å‹ID
    
    Request Body:
        enabled (bool): æ˜¯å¦å¯ç”¨è‡ªåŠ¨äº¤æ˜“
    
    Returns:
        JSON: æ›´æ–°åçš„è‡ªåŠ¨äº¤æ˜“çŠ¶æ€
    """
    data = request.json or {}
    if 'enabled' not in data:
        return jsonify({'error': 'enabled flag is required'}), 400

    model = db.get_model(model_id)
    if not model:
        return jsonify({'error': 'Model not found'}), 404

    enabled = bool(data.get('enabled'))
    success = db.set_model_auto_trading(model_id, enabled)
    if not success:
        return jsonify({'error': 'Failed to update model status'}), 500

    if enabled and model_id not in trading_engines:
        init_trading_engine_for_model(model_id)

    return jsonify({'model_id': model_id, 'auto_trading_enabled': enabled})

@app.route('/api/aggregated/portfolio', methods=['GET'])
def get_aggregated_portfolio():
    """
    è·å–æ‰€æœ‰æ¨¡å‹çš„èšåˆæŠ•èµ„ç»„åˆæ•°æ®
    
    Returns:
        JSON: åŒ…å«æ‰€æœ‰æ¨¡å‹çš„æ±‡æ€»æŠ•èµ„ç»„åˆã€å›¾è¡¨æ•°æ®ç­‰ä¿¡æ¯
    """
    symbols = get_tracked_symbols()
    prices_data = market_fetcher.get_current_prices(symbols)
    current_prices = {symbol: data['price'] for symbol, data in prices_data.items()}

    models = db.get_all_models()
    total_portfolio = {
        'total_value': 0,
        'cash': 0,
        'positions_value': 0,
        'realized_pnl': 0,
        'unrealized_pnl': 0,
        'initial_capital': 0,
        'positions': []
    }

    all_positions = {}

    for model in models:
        portfolio = db.get_portfolio(model['id'], current_prices)
        if portfolio:
            total_portfolio['total_value'] += portfolio.get('total_value', 0)
            total_portfolio['cash'] += portfolio.get('cash', 0)
            total_portfolio['positions_value'] += portfolio.get('positions_value', 0)
            total_portfolio['realized_pnl'] += portfolio.get('realized_pnl', 0)
            total_portfolio['unrealized_pnl'] += portfolio.get('unrealized_pnl', 0)
            total_portfolio['initial_capital'] += portfolio.get('initial_capital', 0)

            # Aggregate positions by symbol and position_side
            for pos in portfolio.get('positions', []):
                symbol = pos.get('symbol', '')
                position_side = pos.get('position_side', 'LONG')
                position_amt = abs(pos.get('position_amt', 0.0))
                
                key = f"{symbol}_{position_side}"
                if key not in all_positions:
                    all_positions[key] = {
                        'symbol': symbol,
                        'position_side': position_side,
                        'position_amt': 0,
                        'avg_price': 0,
                        'total_cost': 0,
                        'leverage': pos.get('leverage', 1),
                        'current_price': pos.get('current_price'),
                        'pnl': pos.get('pnl', 0)
                    }

                # Weighted average calculation
                current_pos = all_positions[key]
                current_cost = current_pos['position_amt'] * current_pos['avg_price']
                new_cost = position_amt * pos.get('avg_price', 0)
                total_position_amt = current_pos['position_amt'] + position_amt

                if total_position_amt > 0:
                    current_pos['avg_price'] = (current_cost + new_cost) / total_position_amt
                    current_pos['position_amt'] = total_position_amt
                    current_pos['total_cost'] = current_cost + new_cost
                    current_pos['pnl'] = (pos.get('current_price', 0) - current_pos['avg_price']) * total_position_amt

    total_portfolio['positions'] = list(all_positions.values())
    chart_data = db.get_multi_model_chart_data(limit=100)

    return jsonify({
        'portfolio': total_portfolio,
        'chart_data': chart_data,
        'model_count': len(models)
    })

# ============ Market Data API Endpoints ============
# å¸‚åœºæ•°æ®æ¥å£ï¼šæä¾›å®æ—¶å¸‚åœºè¡Œæƒ…ã€æ¶¨è·Œå¹…æ¦œã€Kçº¿æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡ç­‰

@app.route('/api/market/prices', methods=['GET'])
def get_market_prices():
    """è·å–å½“å‰å¸‚åœºä»·æ ¼ï¼ˆä»…è¿”å›é…ç½®çš„åˆçº¦ä¿¡æ¯ï¼‰
    
    Returns:
        JSON: ä»·æ ¼æ•°æ®å­—å…¸ï¼Œkeyä¸ºäº¤æ˜“å¯¹ç¬¦å·ï¼ŒvalueåŒ…å«ä»·æ ¼å’Œæ¥æºä¿¡æ¯
    """
    # è·å–é…ç½®çš„åˆçº¦
    configured_symbols = get_tracked_symbols()
    configured_prices = market_fetcher.get_prices(configured_symbols)
    
    # ä¸ºé…ç½®çš„åˆçº¦æ·»åŠ æ¥æºæ ‡è®°
    for symbol in configured_prices:
        configured_prices[symbol]['source'] = 'configured'
    
    return jsonify(configured_prices)

@app.route('/api/market/indicators/<symbol>', methods=['GET'])
def get_market_indicators(symbol):
    """Get technical indicators for a specific symbol
    
    ä»å¸å®‰APIå®æ—¶è·å–å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
    - Kçº¿æ•°æ®ï¼ˆå¼€é«˜ä½æ”¶ã€æˆäº¤é‡ï¼‰
    - MAå‡çº¿ï¼ˆ5ã€20ã€60ã€99å‘¨æœŸï¼‰
    - MACDæŒ‡æ ‡ï¼ˆDIFã€DEAã€BARï¼‰
    - RSIæŒ‡æ ‡ï¼ˆRSI6ã€RSI9ï¼‰
    - æˆäº¤é‡ï¼ˆVOLï¼‰
    
    æ—¶é—´æ¡†æ¶ï¼š1å‘¨ã€1å¤©ã€4å°æ—¶ã€1å°æ—¶ã€15åˆ†é’Ÿã€5åˆ†é’Ÿã€1åˆ†é’Ÿ
    
    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ 'BTC'ï¼‰
        
    Returns:
        æŠ€æœ¯æŒ‡æ ‡æ•°æ®å­—å…¸ï¼Œæ ¼å¼ï¼š{'timeframes': {1w: {...}, 1d: {...}, ...}}
    """
    try:
        indicators = market_fetcher.calculate_technical_indicators(symbol)
        if not indicators:
            return jsonify({
                'symbol': symbol,
                'timeframes': {},
                'error': 'æ— æ³•è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®'
            }), 200
        
        return jsonify({
            'symbol': symbol,
            **indicators
        })
    except Exception as e:
        logger.error(f"[API] Failed to get indicators for {symbol}: {e}", exc_info=True)
        return jsonify({
            'symbol': symbol,
            'timeframes': {},
            'error': str(e)
        }), 500

@app.route('/api/market/leaderboard/gainers', methods=['GET'])
def get_market_leaderboard_gainers():
    """Get market gainers leaderboard data (æ¶¨å¹…æ¦œ)
    
    ä» 24_market_tickers è¡¨ç›´æ¥æŸ¥è¯¢æ¶¨å¹…æ¦œæ•°æ®ï¼š
    - æŸ¥è¯¢ side='gainer' çš„è®°å½•
    - æŒ‰ price_change_percent é™åºæ’åº
    - è¿”å›å‰Nå
    
    å‰ç«¯é€šè¿‡è½®è¯¢æ­¤æ¥å£è·å–æ¶¨å¹…æ¦œæ•°æ®
    """
    limit = request.args.get('limit', type=int) or 10  # é»˜è®¤10æ¡
    
    try:
        from common.database_mysql import MySQLDatabase
        db = MySQLDatabase(auto_init_tables=False)
        
        # ä» 24_market_tickers è¡¨ç›´æ¥æŸ¥è¯¢æ¶¨å¹…æ¦œ
        gainers = db.get_gainers_from_tickers(limit=limit)
        
        result = {
            'gainers': gainers,
            'timestamp': int(datetime.now(timezone(timedelta(hours=8))).timestamp() * 1000)
        }
        
        logger.debug(f"[API] æ¶¨å¹…æ¦œæ•°æ®è¿”å›: {len(gainers)} æ¡")
        return jsonify(result)
    except Exception as exc:
        logger.error(f"Failed to load gainers leaderboard: {exc}", exc_info=True)
        return jsonify({'error': str(exc), 'gainers': []}), 500

@app.route('/api/market/leaderboard/losers', methods=['GET'])
def get_market_leaderboard_losers():
    """Get market losers leaderboard data (è·Œå¹…æ¦œ)
    
    ä» 24_market_tickers è¡¨ç›´æ¥æŸ¥è¯¢è·Œå¹…æ¦œæ•°æ®ï¼š
    - æŸ¥è¯¢ side='loser' çš„è®°å½•
    - æŒ‰ price_change_percent ç»å¯¹å€¼é™åºæ’åºï¼ˆæ³¨æ„ price_change_percent ä¸ºè´Ÿå€¼ï¼‰
    - è¿”å›å‰Nå
    
    å‰ç«¯é€šè¿‡è½®è¯¢æ­¤æ¥å£è·å–è·Œå¹…æ¦œæ•°æ®
    """
    limit = request.args.get('limit', type=int) or 10  # é»˜è®¤10æ¡
    
    try:
        from common.database_mysql import MySQLDatabase
        db = MySQLDatabase(auto_init_tables=False)
        
        # ä» 24_market_tickers è¡¨ç›´æ¥æŸ¥è¯¢è·Œå¹…æ¦œ
        losers = db.get_losers_from_tickers(limit=limit)
        
        result = {
            'losers': losers,
            'timestamp': int(datetime.now(timezone(timedelta(hours=8))).timestamp() * 1000)
        }
        
        logger.debug(f"[API] è·Œå¹…æ¦œæ•°æ®è¿”å›: {len(losers)} æ¡")
        return jsonify(result)
    except Exception as exc:
        logger.error(f"Failed to load losers leaderboard: {exc}", exc_info=True)
        return jsonify({'error': str(exc), 'losers': []}), 500

@app.route('/api/market/leaderboard', methods=['GET'])
def get_market_leaderboard():
    """
    è·å–æ¶¨è·Œå¹…æ¦œæ•°æ®ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰
    
    æ³¨æ„ï¼šæ­¤æ¥å£å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ /api/market/leaderboard/gainers å’Œ /api/market/leaderboard/losers
    
    Query Parameters:
        limit (int, optional): è¿”å›è®°å½•æ•°é™åˆ¶ï¼Œé»˜è®¤10
        force (int, optional): æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼Œé»˜è®¤0
    
    Returns:
        JSON: åŒ…å«æ¶¨å¹…æ¦œå’Œè·Œå¹…æ¦œæ•°æ®
    """
    limit = request.args.get('limit', type=int) or 10
    force = request.args.get('force', default=0, type=int)
    
    try:
        # è·å–æ¶¨è·Œå¹…æ¦œæ•°æ®ï¼ˆæ¶¨10ä¸ªï¼Œè·Œ10ä¸ªï¼‰
        data = market_fetcher.sync_leaderboard(force=bool(force), limit=limit)
        
        # ç¡®ä¿è¿”å›å®Œæ•´æ•°æ®æ ¼å¼
        result = {
            'gainers': data.get('gainers', [])[:limit],
            'losers': data.get('losers', [])[:limit],
            'timestamp': int(datetime.now(timezone(timedelta(hours=8))).timestamp() * 1000)
        }
        
        gainers_count = len(result['gainers'])
        losers_count = len(result['losers'])
        logger.debug(f"[API] æ¶¨è·Œå¹…æ¦œæ•°æ®è¿”å›: æ¶¨å¹…æ¦œ {gainers_count} æ¡, è·Œå¹…æ¦œ {losers_count} æ¡")
        
        return jsonify(result)
    except Exception as exc:
        logger.error(f"Failed to load leaderboard: {exc}", exc_info=True)
        return jsonify({'error': str(exc), 'gainers': [], 'losers': []}), 500

@app.route('/api/market/klines', methods=['GET'])
def get_market_klines():
    """è·å–Kçº¿å†å²æ•°æ®
    
    å‚æ•°:
        symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ 'BTCUSDT'ï¼‰
        interval: æ—¶é—´é—´éš”ï¼ˆ'1m', '5m', '15m', '1h', '4h', '1d', '1w'ï¼‰
        limit: è¿”å›çš„æœ€å¤§è®°å½•æ•°ï¼Œé»˜è®¤å€¼æ ¹æ®intervalä¸åŒï¼š
               - 1dï¼ˆ1å¤©ï¼‰ï¼šé»˜è®¤120æ¡ï¼Œæœ€å¤§120æ¡
               - 1wï¼ˆ1å‘¨ï¼‰ï¼šé»˜è®¤20æ¡ï¼Œæœ€å¤§20æ¡
               - å…¶ä»–intervalï¼šé»˜è®¤499æ¡ï¼Œæœ€å¤§499æ¡
        start_time: å¼€å§‹æ—¶é—´ï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆå¯é€‰ï¼ŒISOæ ¼å¼å­—ç¬¦ä¸²ï¼‰
    """
    try:
        from datetime import datetime
        from common.config import KLINE_DATA_SOURCE
        
        symbol = request.args.get('symbol', '').upper()
        interval = request.args.get('interval', '5m')
        # æ ¹æ®æ•°æ®æºè®¾ç½®ä¸åŒçš„é»˜è®¤limit
        source = KLINE_DATA_SOURCE  # ä»é…ç½®æ–‡ä»¶è·å–æ•°æ®æºï¼Œä¸å†ä»è¯·æ±‚å‚æ•°è·å–
        
        # æ ¹æ®ä¸åŒçš„intervalè®¾ç½®ä¸åŒçš„é»˜è®¤limit
        # 1dï¼ˆ1å¤©ï¼‰ï¼š120æ¡ï¼ˆçº¦4ä¸ªæœˆå†å²æ•°æ®ï¼‰
        # 1wï¼ˆ1å‘¨ï¼‰ï¼š20æ¡ï¼ˆçº¦5ä¸ªæœˆå†å²æ•°æ®ï¼‰
        # å…¶ä»–intervalï¼š499æ¡
        interval_default_limits = {
            '1d': 499,  # 1å¤©å‘¨æœŸï¼Œé»˜è®¤499æ¡
            '1w': 99,   # 1å‘¨å‘¨æœŸï¼Œé»˜è®¤99æ¡
        }
        default_limit = interval_default_limits.get(interval, 499)  # å…¶ä»–å‘¨æœŸé»˜è®¤500æ¡
        
        limit = request.args.get('limit', type=int) or default_limit
        start_time_str = request.args.get('start_time')
        end_time_str = request.args.get('end_time')
        
        if not symbol:
            return jsonify({'error': 'symbol parameter is required'}), 400
        
        # éªŒè¯interval
        valid_intervals = ['1m', '5m', '15m', '1h', '4h', '1d', '1w']
        if interval not in valid_intervals:
            return jsonify({'error': f'invalid interval. Must be one of: {valid_intervals}'}), 400
        
        # è§£ææ—¶é—´å‚æ•°
        start_time = None
        end_time = None
        start_timestamp = None
        end_timestamp = None
        
        if start_time_str:
            try:
                start_time = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
                start_timestamp = int(start_time.timestamp() * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            except ValueError:
                return jsonify({'error': 'invalid start_time format. Use ISO format'}), 400
        
        if end_time_str:
            try:
                end_time = datetime.fromisoformat(end_time_str.replace('Z', '+00:00'))
                end_timestamp = int(end_time.timestamp() * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            except ValueError:
                return jsonify({'error': 'invalid end_time format. Use ISO format'}), 400
        
        # è·å–å®¢æˆ·ç«¯IPåœ°å€
        client_ip = request.remote_addr
        
        # æŸ¥è¯¢Kçº¿æ•°æ®ï¼Œæ·»åŠ å®¢æˆ·ç«¯IPä¿¡æ¯
        logger.info(f"[API] è·å–Kçº¿å†å²æ•°æ®è¯·æ±‚: symbol={symbol}, interval={interval}, limit={limit}, source={source}, start_time={start_time_str}, end_time={end_time_str}, client_ip={client_ip}")
        
        klines = []
        
        if source == 'db':
            # ä»æ•°æ®åº“è·å–æ•°æ®
            from common.database_mysql import MySQLDatabase
            logger.info(f"[API] ä»æ•°æ®åº“è·å–Kçº¿æ•°æ®: symbol={symbol}, interval={interval}")
            mysql_db = MySQLDatabase(auto_init_tables=False)
            klines = mysql_db.get_market_klines(
                symbol=symbol,
                interval=interval,
                limit=limit,
                start_time=start_time,
                end_time=end_time
            )
        else:
            # ä»SDKè·å–æ•°æ®ï¼ˆé»˜è®¤ï¼‰
            # ä½¿ç”¨å…¨å±€market_fetcherå˜é‡ï¼Œè€Œéé‡æ–°å¯¼å…¥
            
            # SDKæ¨¡å¼ä¸‹æ ¹æ®ä¸åŒçš„intervalè®¾ç½®ä¸åŒçš„æœ€å¤§limit
            # 1dï¼ˆ1å¤©ï¼‰ï¼šæœ€å¤§120æ¡
            # 1wï¼ˆ1å‘¨ï¼‰ï¼šæœ€å¤§20æ¡
            # å…¶ä»–intervalï¼šæœ€å¤§500æ¡
            interval_max_limits = {
                '1d': 120,  # 1å¤©å‘¨æœŸï¼Œæœ€å¤§120æ¡
                '1w': 20,   # 1å‘¨å‘¨æœŸï¼Œæœ€å¤§20æ¡
            }
            max_limit = interval_max_limits.get(interval, 499)  # å…¶ä»–å‘¨æœŸæœ€å¤§500æ¡
            
            sdk_limit = limit
            if sdk_limit > max_limit:
                sdk_limit = max_limit
                logger.debug(f"[API] SDKæ¨¡å¼ä¸‹é™åˆ¶limitä¸º{max_limit}ï¼ˆinterval={interval}ï¼‰ï¼ŒåŸè¯·æ±‚limit={limit}")
            
            logger.info(f"[API] ä»SDKè·å–Kçº¿æ•°æ®: symbol={symbol}, interval={interval}, limit={sdk_limit}")
            
            # è°ƒç”¨SDKè·å–Kçº¿æ•°æ®ï¼ˆåªä¼ å…¥endTimeï¼Œä¸ä¼ å…¥startTimeï¼‰
            klines_raw = market_fetcher._futures_client.get_klines(
                symbol=symbol,
                interval=interval,
                limit=sdk_limit,
                startTime=start_timestamp,  # å¦‚æœæä¾›äº†startTimeï¼Œä¹Ÿä¼ å…¥
                endTime=end_timestamp  # åªä¼ å…¥endTimeï¼ˆæˆ–ä¼ å…¥çš„endTimeï¼‰
            )
            
            if not klines_raw or len(klines_raw) == 0:
                logger.warning(f"[API] SDKæœªè¿”å›Kçº¿æ•°æ®: symbol={symbol}, interval={interval}")
                klines = []
            else:
                # SDKè¿”å›çš„æ•°æ®æ˜¯å€’åºçš„ï¼ˆä»æ–°åˆ°æ—§ï¼‰ï¼Œæ•°ç»„[0]æ˜¯æœ€æ–°çš„Kçº¿ï¼Œæ•°ç»„[-1]æ˜¯æœ€æ—§çš„Kçº¿
                # æ³¨æ„ï¼šKçº¿é¡µé¢å·²æ”¹ä¸ºä»…ä½¿ç”¨å†å²æ•°æ®ï¼Œä¸å†è®¢é˜…å®æ—¶Kçº¿æ›´æ–°ï¼Œå› æ­¤ä¿ç•™æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬æœ€æ–°Kçº¿ï¼‰
                logger.debug(f"[API] SDKè¿”å›{len(klines_raw)}æ¡Kçº¿æ•°æ®ï¼ˆå€’åºï¼šæœ€æ–°â†’æœ€æ—§ï¼‰ï¼Œä¿ç•™æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬æœ€æ–°Kçº¿ï¼‰")
                
                # è½¬æ¢SDKè¿”å›æ•°æ®ä¸ºç»Ÿä¸€æ ¼å¼ï¼Œä»·æ ¼ä¿ç•™6ä½å°æ•°
                formatted_klines = []
                for kline in klines_raw:
                    # è·å–åŸå§‹ä»·æ ¼æ•°æ®ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—ï¼‰
                    raw_open = kline.get('open', 0)
                    raw_high = kline.get('high', 0)
                    raw_low = kline.get('low', 0)
                    raw_close = kline.get('close', 0)
                    
                    # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶ä¿ç•™6ä½å°æ•°
                    formatted_open = round(float(raw_open) if raw_open else 0.0, 6)
                    formatted_high = round(float(raw_high) if raw_high else 0.0, 6)
                    formatted_low = round(float(raw_low) if raw_low else 0.0, 6)
                    formatted_close = round(float(raw_close) if raw_close else 0.0, 6)
                    
                    formatted_klines.append({
                        'timestamp': kline.get('open_time', 0),
                        'open': formatted_open,
                        'high': formatted_high,
                        'low': formatted_low,
                        'close': formatted_close,
                        'volume': float(kline.get('volume', 0)),
                        'turnover': float(kline.get('quote_asset_volume', 0))
                    })
                
                # ç”±äºSDKè¿”å›çš„æ•°æ®æ˜¯å€’åºçš„ï¼ˆä»æ–°åˆ°æ—§ï¼‰ï¼Œéœ€è¦æŒ‰timestampå‡åºæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
                # ç¡®ä¿ä¸æ•°æ®åº“æ¨¡å¼å’Œå‰ç«¯æœŸæœ›çš„æ•°æ®é¡ºåºä¸€è‡´
                # å‰ç«¯Kçº¿å›¾è¡¨ä»å·¦åˆ°å³æ˜¾ç¤ºï¼Œå·¦è¾¹æ˜¯æœ€æ—§çš„æ•°æ®ï¼Œå³è¾¹æ˜¯æœ€æ–°çš„æ•°æ®ï¼Œæ‰€ä»¥éœ€è¦ä»æ—§åˆ°æ–°çš„é¡ºåº
                formatted_klines.sort(key=lambda x: x.get('timestamp', 0))
                klines = formatted_klines
                
                logger.info(f"[API] SDKæŸ¥è¯¢å®Œæˆï¼Œå…±è·å– {len(klines)} æ¡Kçº¿æ•°æ®ï¼ˆå·²æ’åºä¸ºä»æ—§åˆ°æ–°ï¼ŒåŒ…å«æœ€æ–°Kçº¿ï¼‰")
                
                # éªŒè¯æ•°æ®é¡ºåºï¼šç¡®ä¿ç¬¬ä¸€æ¡æ—¶é—´æˆ³å°äºæœ€åä¸€æ¡æ—¶é—´æˆ³ï¼ˆä»æ—§åˆ°æ–°ï¼Œtimestampå‡åºï¼‰
                # å‰ç«¯Kçº¿å›¾è¡¨ä»å·¦åˆ°å³æ˜¾ç¤ºï¼Œå·¦è¾¹æ˜¯æœ€æ—§çš„æ•°æ®ï¼ˆç¬¬ä¸€æ¡ï¼‰ï¼Œå³è¾¹æ˜¯æœ€æ–°çš„æ•°æ®ï¼ˆæœ€åä¸€æ¡ï¼‰
                # æ‰€ä»¥æ•°æ®é¡ºåºåº”è¯¥æ˜¯ï¼šç¬¬ä¸€æ¡ï¼ˆæœ€æ—§ï¼‰< æœ€åä¸€æ¡ï¼ˆæœ€æ–°ï¼‰
                if len(klines) > 1:
                    first_timestamp = klines[0].get('timestamp', 0)
                    last_timestamp = klines[-1].get('timestamp', 0)
                    
                    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetimeæ ¼å¼ä¾¿äºæ’æŸ¥
                    def format_timestamp_for_validation(ts):
                        """å°†timestampï¼ˆæ¯«ç§’ï¼‰è½¬æ¢ä¸ºdatetimeå­—ç¬¦ä¸²ç”¨äºéªŒè¯"""
                        if ts == 0 or ts is None:
                            return 'N/A'
                        try:
                            from datetime import timezone as tz
                            dt = datetime.fromtimestamp(ts / 1000, tz=tz.utc)
                            return dt.strftime('%Y-%m-%d %H:%M:%S UTC')
                        except (ValueError, TypeError, OSError) as e:
                            return f'{ts} (è½¬æ¢å¤±è´¥: {e})'
                    
                    first_timestamp_dt = format_timestamp_for_validation(first_timestamp)
                    last_timestamp_dt = format_timestamp_for_validation(last_timestamp)
                    
                    if first_timestamp >= last_timestamp:
                        logger.warning(
                            f"[API] âš ï¸ æ•°æ®é¡ºåºå¼‚å¸¸ï¼šç¬¬ä¸€æ¡æ—¶é—´æˆ³({first_timestamp}, {first_timestamp_dt}) >= "
                            f"æœ€åä¸€æ¡({last_timestamp}, {last_timestamp_dt})ï¼Œ"
                            f"é‡æ–°æ’åºä»¥ç¡®ä¿ä»æ—§åˆ°æ–°çš„é¡ºåºï¼ˆä¸å‰ç«¯Kçº¿å›¾è¡¨ä»å·¦åˆ°å³çš„è¦æ±‚ä¸€è‡´ï¼‰"
                        )
                        klines.sort(key=lambda x: x.get('timestamp', 0))
                        # é‡æ–°éªŒè¯
                        first_timestamp = klines[0].get('timestamp', 0)
                        last_timestamp = klines[-1].get('timestamp', 0)
                        first_timestamp_dt = format_timestamp_for_validation(first_timestamp)
                        last_timestamp_dt = format_timestamp_for_validation(last_timestamp)
                        logger.debug(
                            f"[API] âœ“ é‡æ–°æ’åºåï¼šç¬¬ä¸€æ¡æ—¶é—´æˆ³={first_timestamp} ({first_timestamp_dt}), "
                            f"æœ€åä¸€æ¡æ—¶é—´æˆ³={last_timestamp} ({last_timestamp_dt})"
                        )
                    else:
                        logger.debug(
                            f"[API] âœ“ æ•°æ®é¡ºåºéªŒè¯é€šè¿‡ï¼šç¬¬ä¸€æ¡æ—¶é—´æˆ³={first_timestamp} ({first_timestamp_dt}) < "
                            f"æœ€åä¸€æ¡æ—¶é—´æˆ³={last_timestamp} ({last_timestamp_dt}) "
                            f"ï¼ˆä»æ—§åˆ°æ–°ï¼Œç¬¦åˆå‰ç«¯Kçº¿å›¾è¡¨ä»å·¦åˆ°å³çš„æ˜¾ç¤ºè¦æ±‚ï¼‰"
                        )
        
        # è®°å½•è¿”å›æ•°æ®ä¿¡æ¯ï¼Œæ·»åŠ å®¢æˆ·ç«¯IP
        klines_count = len(klines) if klines else 0
        logger.info(f"[API] è·å–Kçº¿å†å²æ•°æ®æŸ¥è¯¢å®Œæˆ: symbol={symbol}, interval={interval}, source={source}, è¿”å›æ•°æ®æ¡æ•°={klines_count}, client_ip={client_ip}")
        
        if klines_count > 0:
            # è®°å½•ç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´æˆ³ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            first_kline = klines[0]
            last_kline = klines[-1]
            first_timestamp = first_kline.get('timestamp', 'N/A')
            last_timestamp = last_kline.get('timestamp', 'N/A')
            
            # å°†timestampè½¬æ¢ä¸ºdatetimeæ ¼å¼ä¾¿äºæ’æŸ¥
            def format_timestamp(ts):
                """å°†timestampï¼ˆæ¯«ç§’ï¼‰è½¬æ¢ä¸ºdatetimeå­—ç¬¦ä¸²"""
                if ts == 'N/A' or ts is None:
                    return 'N/A'
                try:
                    # timestampæ˜¯æ¯«ç§’æ—¶é—´æˆ³ï¼Œéœ€è¦é™¤ä»¥1000
                    from datetime import timezone as tz
                    dt = datetime.fromtimestamp(ts / 1000, tz=tz.utc)
                    return dt.strftime('%Y-%m-%d %H:%M:%S UTC')
                except (ValueError, TypeError, OSError) as e:
                    return f'{ts} (è½¬æ¢å¤±è´¥: {e})'
            
            first_timestamp_dt = format_timestamp(first_timestamp)
            last_timestamp_dt = format_timestamp(last_timestamp)
            
            logger.info(
                f"[API] è·å–Kçº¿å†å²æ•°æ®æ—¶é—´èŒƒå›´: "
                f"ç¬¬ä¸€æ¡timestamp={first_timestamp} ({first_timestamp_dt}), "
                f"æœ€åä¸€æ¡timestamp={last_timestamp} ({last_timestamp_dt}), "
                f"å…±è¿”å›{klines_count}æ¡æ•°æ®, client_ip={client_ip}"
            )
            
            # è®°å½•ç¬¬ä¸€æ¡æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•æ•°æ®æ ¼å¼ï¼‰
            logger.debug(f"[API] è·å–Kçº¿å†å²æ•°æ®ç¤ºä¾‹ï¼ˆç¬¬ä¸€æ¡ï¼‰: {first_kline}")
            logger.debug(f"[API] è·å–Kçº¿å†å²æ•°æ®ç¤ºä¾‹ï¼ˆæœ€åä¸€æ¡ï¼‰: {last_kline}")
        else:
            logger.warning(f"[API]  æœªæ‰¾åˆ°Kçº¿å†å²æ•°æ®: symbol={symbol}, interval={interval}, client_ip={client_ip}")
        
        response_data = {
            'symbol': symbol,
            'interval': interval,
            'source': source,
            'data': klines,
            'count': klines_count  # æ·»åŠ æ•°æ®æ¡æ•°å­—æ®µï¼Œä¾¿äºå‰ç«¯è°ƒè¯•
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"[API] è·å–Kçº¿æ•°æ®å¤±è´¥: symbol={symbol}, interval={interval}, source={source}, error={e}", exc_info=True)
        return jsonify({'error': str(e)}), 500

# ============ WebSocket Handlers ============
# WebSocketäº‹ä»¶å¤„ç†ï¼šç”¨äºå®æ—¶æ•°æ®æ¨é€ï¼ˆKçº¿æ•°æ®ç­‰ï¼‰

@socketio.on('klines:subscribe')
def handle_klines_subscribe(payload=None):
    """
    WebSocketå¤„ç†ï¼šè®¢é˜…Kçº¿å®æ—¶æ•°æ®æ¨é€
    
    Args:
        payload (dict): è®¢é˜…å‚æ•°
            symbol (str): äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ 'BTCUSDT'ï¼‰
            interval (str): æ—¶é—´é—´éš”ï¼ˆ'1m', '5m', '15m', '1h', '4h', '1d', '1w'ï¼‰
    
    Note:
        è®¢é˜…åï¼Œå®¢æˆ·ç«¯å°†å®šæœŸæ”¶åˆ°è¯¥äº¤æ˜“å¯¹çš„Kçº¿æ›´æ–°æ•°æ®
    """
    payload = payload or {}
    symbol = payload.get('symbol', '').upper()
    interval = payload.get('interval', '5m')
    
    # è®°å½•å‡½æ•°è°ƒç”¨ä¿¡æ¯
    logger.info(f"[KLine Subscribe] Received subscription request: payload={payload}, symbol={symbol}, interval={interval}")
    
    if not symbol:
        logger.warning(f"[KLine Subscribe] Subscription failed: symbol is required, payload={payload}")
        emit('klines:error', {'message': 'symbol is required'})
        return
    
    valid_intervals = ['1m', '5m', '15m', '1h', '4h', '1d', '1w']
    if interval not in valid_intervals:
        logger.warning(f"[KLine Subscribe] Subscription failed: invalid interval '{interval}', must be one of {valid_intervals}")
        emit('klines:error', {'message': f'invalid interval. Must be one of: {valid_intervals}'})
        return
    
    # åŠ å…¥æˆ¿é—´ï¼ˆæŒ‰symbolå’Œintervalåˆ†ç»„ï¼‰
    room = f'klines:{symbol}:{interval}'
    from flask_socketio import join_room
    join_room(room)
    logger.debug(f"[KLine Subscribe] Client joined room: {room}")
    
    # è®°å½•è®¢é˜…å‰åçš„è®¢é˜…æ•°é‡
    with kline_push_lock:
        previous_count = len(kline_subscriptions)
        kline_subscriptions[room] = {
            'symbol': symbol,
            'interval': interval,
            'last_update_time': datetime.now(timezone(timedelta(hours=8)))
        }
        current_count = len(kline_subscriptions)
    
    logger.info(f"[KLine Subscribe] Subscription added: room={room}, symbol={symbol}, interval={interval}, " \
                f"subscriptions_count: {previous_count} â†’ {current_count}")
    
    # å¯åŠ¨æ¨é€å·¥ä½œçº¿ç¨‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å¯åŠ¨ï¼‰
    start_kline_push_worker()
    logger.debug(f"[KLine Subscribe] Push worker started/checked")
    
    # å‘é€è®¢é˜…æˆåŠŸäº‹ä»¶
    emit('klines:subscribed', {'symbol': symbol, 'interval': interval})
    logger.info(f"[KLine Subscribe] Subscription completed: symbol={symbol}, interval={interval}, room={room}, " \
                f"total_subscriptions={current_count}")

@socketio.on('klines:unsubscribe')
def handle_klines_unsubscribe(payload=None):
    """
    WebSocketå¤„ç†ï¼šå–æ¶ˆKçº¿è®¢é˜…
    
    Args:
        payload (dict): å–æ¶ˆè®¢é˜…å‚æ•°
            symbol (str): äº¤æ˜“å¯¹ç¬¦å·ï¼ˆå¦‚ 'BTCUSDT'ï¼‰
            interval (str): æ—¶é—´é—´éš”ï¼ˆ'1m', '5m', '15m', '1h', '4h', '1d', '1w'ï¼‰
    """
    payload = payload or {}
    symbol = payload.get('symbol', '').upper()
    interval = payload.get('interval', '5m')
    
    # è®°å½•å‡½æ•°è°ƒç”¨ä¿¡æ¯
    logger.info(f"[KLine Unsubscribe] Received unsubscribe request: payload={payload}, symbol={symbol}, interval={interval}")
    
    room = f'klines:{symbol}:{interval}'
    from flask_socketio import leave_room
    
    # è®°å½•å®¢æˆ·ç«¯ç¦»å¼€æˆ¿é—´ä¿¡æ¯
    logger.debug(f"[KLine Unsubscribe] Client leaving room: {room}")
    leave_room(room)
    
    # ç§»é™¤è®¢é˜…ä¿¡æ¯
    with kline_push_lock:
        previous_count = len(kline_subscriptions)
        was_subscribed = room in kline_subscriptions
        
        if was_subscribed:
            del kline_subscriptions[room]
            current_count = len(kline_subscriptions)
            logger.info(f"[KLine Unsubscribe] Subscription removed: room={room}, symbol={symbol}, interval={interval}, subscriptions_count: {previous_count} â†’ {current_count}")
        else:
            current_count = previous_count
            logger.warning(f"[KLine Unsubscribe] Room not found in subscriptions: room={room}, symbol={symbol}, interval={interval}")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ´»è·ƒè®¢é˜…ï¼Œå¦‚æœæ²¡æœ‰åˆ™å…³é—­æ¨é€çº¿ç¨‹
        if not kline_subscriptions:
            kline_push_stop_event.set()
            logger.info("[KLine Unsubscribe] No active KLine subscriptions, stopping push thread")
    
    # è®°å½•å–æ¶ˆè®¢é˜…å®Œæˆä¿¡æ¯
    logger.info(f"[KLine Unsubscribe] Client unsubscribed from klines: symbol={symbol}, interval={interval}, room={room}, was_subscribed={was_subscribed}")
    emit('klines:unsubscribed', {'symbol': symbol, 'interval': interval})

# Kçº¿å®æ—¶æ¨é€ç›¸å…³å˜é‡
kline_subscriptions = {}  # å­˜å‚¨è®¢é˜…ä¿¡æ¯: {room: {symbol, interval, last_update_time}}
kline_push_thread = None
kline_push_stop_event = threading.Event()
kline_push_lock = threading.Lock()

def push_realtime_kline(symbol: str, interval: str):
    """æ¨é€å®æ—¶Kçº¿æ•°æ®åˆ°è®¢é˜…çš„å®¢æˆ·ç«¯"""
    try:
        if not market_fetcher._futures_client:
            return
        
        # è·å–æœ€æ–°Kçº¿æ•°æ®
        contract_symbol = market_fetcher._futures_client.format_symbol(symbol)
        klines = market_fetcher._futures_client.get_klines(
            contract_symbol,
            interval,
            limit=1
        )
        
        if klines and len(klines) > 0:
            latest_kline = klines[-1]
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            kline_data = {
                'timestamp': int(latest_kline.get('close_time', latest_kline.get('open_time', 0))),
                'open': float(latest_kline.get('open', 0)),
                'high': float(latest_kline.get('high', 0)),
                'low': float(latest_kline.get('low', 0)),
                'close': float(latest_kline.get('close', 0)),
                'volume': float(latest_kline.get('volume', 0)),
                'turnover': float(latest_kline.get('quote_asset_volume', 0))
            }
            
            # æ¨é€åˆ°è®¢é˜…çš„æˆ¿é—´
            room = f'klines:{contract_symbol}:{interval}'
            socketio.emit('klines:update', {
                'symbol': contract_symbol,
                'interval': interval,
                'kline': kline_data
            }, room=room)
            
    except Exception as e:
        logger.error(f"Failed to push realtime kline for {symbol} {interval}: {e}", exc_info=True)

def _kline_push_loop():
    """åå°å¾ªç¯ä»»åŠ¡ï¼šå®šæœŸæ¨é€å®æ—¶Kçº¿æ•°æ®åˆ°è®¢é˜…çš„å®¢æˆ·ç«¯"""
    global kline_push_thread
    thread_id = threading.current_thread().ident
    logger.info(f"[KLine Push Worker-{thread_id}] Kçº¿å®æ—¶æ¨é€å¾ªç¯å¯åŠ¨")
    
    # æ ¹æ®æœ€å°å‘¨æœŸï¼ˆ1mï¼‰è®¾ç½®æ¨é€é—´éš”
    push_interval = 5  # æ¯5ç§’æ¨é€ä¸€æ¬¡
    
    while not kline_push_stop_event.is_set():
        try:
            with kline_push_lock:
                # è·å–æ‰€æœ‰æ´»è·ƒçš„è®¢é˜…
                active_subscriptions = dict(kline_subscriptions)
            
            if not active_subscriptions:
                # æ²¡æœ‰è®¢é˜…ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                kline_push_stop_event.wait(push_interval)
                continue
            
            # éå†æ‰€æœ‰è®¢é˜…å¹¶æ¨é€æ•°æ®
            for room, subscription_info in active_subscriptions.items():
                try:
                    symbol = subscription_info.get('symbol')
                    interval = subscription_info.get('interval')
                    
                    if symbol and interval:
                        push_realtime_kline(symbol, interval)
                except Exception as e:
                    logger.error(f"[KLine Push Worker] Error pushing kline for {room}: {e}", exc_info=True)
            
            # ç­‰å¾…æŒ‡å®šé—´éš”
            kline_push_stop_event.wait(push_interval)
            
        except Exception as e:
            logger.error(f"[KLine Push Worker-{thread_id}] Error in push loop: {e}", exc_info=True)
            kline_push_stop_event.wait(push_interval)
    
    logger.info(f"[KLine Push Worker-{thread_id}] Kçº¿å®æ—¶æ¨é€å¾ªç¯åœæ­¢")
    
    # çº¿ç¨‹é€€å‡ºæ—¶é‡ç½®çŠ¶æ€ï¼Œç¡®ä¿ä¸‹æ¬¡èƒ½æ­£ç¡®å¯åŠ¨
    with kline_push_lock:
        kline_push_stop_event.clear()
        kline_push_thread = None

def start_kline_push_worker():
    """å¯åŠ¨Kçº¿å®æ—¶æ¨é€å·¥ä½œçº¿ç¨‹"""
    global kline_push_thread
    if kline_push_thread and kline_push_thread.is_alive():
        return
    kline_push_stop_event.clear()
    kline_push_thread = threading.Thread(target=_kline_push_loop, daemon=True, name="KLinePushWorker")
    kline_push_thread.start()
    logger.info("[KLine Push] Kçº¿å®æ—¶æ¨é€å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")

# ============ Settings API Endpoints ============
# ç³»ç»Ÿè®¾ç½®ç®¡ç†ï¼šç”¨äºé…ç½®äº¤æ˜“é¢‘ç‡ã€æ‰‹ç»­è´¹ç‡ç­‰ç³»ç»Ÿå‚æ•°

@app.route('/api/settings', methods=['GET'])
def get_settings():
    """
    è·å–ç³»ç»Ÿè®¾ç½®
    
    Returns:
        JSON: ç³»ç»Ÿè®¾ç½®ä¿¡æ¯ï¼ŒåŒ…æ‹¬äº¤æ˜“é¢‘ç‡ã€æ‰‹ç»­è´¹ç‡ç­‰
    """
    try:
        settings = db.get_settings()
        return jsonify(settings)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/settings', methods=['PUT'])
def update_settings():
    """
    æ›´æ–°ç³»ç»Ÿè®¾ç½®
    
    Request Body:
        trading_frequency_minutes (int, optional): äº¤æ˜“é¢‘ç‡ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤60
        trading_fee_rate (float, optional): æ‰‹ç»­è´¹ç‡ï¼Œé»˜è®¤0.001
        show_system_prompt (bool, optional): æ˜¯å¦æ˜¾ç¤ºç³»ç»Ÿæç¤ºï¼Œé»˜è®¤False
    
    Returns:
        JSON: æ›´æ–°æ“ä½œç»“æœ
    """
    try:
        data = request.json or {}
        trading_frequency_minutes = int(data.get('trading_frequency_minutes', 60))
        trading_fee_rate = float(data.get('trading_fee_rate', 0.001))
        show_system_prompt = 1 if data.get('show_system_prompt') in (True, 1, '1', 'true', 'True') else 0

        success = db.update_settings(
            trading_frequency_minutes,
            trading_fee_rate,
            show_system_prompt
        )

        if success:
            return jsonify({'success': True, 'message': 'Settings updated successfully'})
        else:
            return jsonify({'success': False, 'error': 'Failed to update settings'}), 500
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ============ Account Management API Endpoints ============
# è´¦æˆ·ç®¡ç†ï¼šç”¨äºæ·»åŠ ã€æŸ¥è¯¢ã€åˆ é™¤äº¤æ˜“è´¦æˆ·ï¼ˆBinance APIå¯†é’¥ç®¡ç†ï¼‰

@app.route('/api/accounts', methods=['GET'])
def get_all_accounts():
    """
    æŸ¥è¯¢æ‰€æœ‰è´¦æˆ·ä¿¡æ¯
    
    Returns:
        JSON: è´¦æˆ·åˆ—è¡¨ï¼ŒåŒ…å«account_nameã€balanceã€crossWalletBalanceç­‰ä¿¡æ¯
    """
    try:
        account_db = AccountDatabase(auto_init_tables=False)
        accounts = account_db.get_all_accounts()
        return jsonify(accounts)
    except Exception as e:
        logger.error(f"Failed to get all accounts: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts', methods=['POST'])
def add_account():
    """
    æ·»åŠ æ–°è´¦æˆ·ï¼ˆé€šè¿‡Binance APIå¯†é’¥éªŒè¯å¹¶ä¿å­˜è´¦æˆ·ä¿¡æ¯ï¼‰
    
    Request Body:
        account_name (str): è´¦æˆ·åç§°ï¼ˆå¿…å¡«ï¼‰
        api_key (str): Binance APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰
        api_secret (str): Binance APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰
    
    Returns:
        JSON: åŒ…å«account_aliaså’ŒæˆåŠŸæ¶ˆæ¯
    
    Note:
        æ­¤æ¥å£ä¼šè°ƒç”¨Binance APIéªŒè¯å¯†é’¥æœ‰æ•ˆæ€§ï¼Œå¹¶è·å–è´¦æˆ·èµ„äº§ä¿¡æ¯
    """
    data = request.json or {}
    account_name = data.get('account_name', '').strip()
    api_key = data.get('api_key', '').strip()
    api_secret = data.get('api_secret', '').strip()
    
    if not account_name:
        return jsonify({'error': 'account_name is required'}), 400
    if not api_key or not api_secret:
        return jsonify({'error': 'api_key and api_secret are required'}), 400
    
    try:
        # 1. åˆ›å»ºBinanceFuturesAccountClientå¯¹è±¡
        client = BinanceFuturesAccountClient(api_key=api_key, api_secret=api_secret)
        
        # 2. è°ƒç”¨get_accountæ–¹æ³•è·å–è´¦æˆ·æ•°æ®ï¼ˆåŒ…å«æ±‡æ€»ä¿¡æ¯å’Œassetsæ•°ç»„ï¼‰
        account_json = client.get_account()
        account_data = json.loads(account_json)
        
        # 3. ä»account_dataä¸­æå–æ±‡æ€»ä¿¡æ¯ï¼ˆç›´æ¥ä½¿ç”¨è¿”å›çš„å­—æ®µï¼‰
        account_asset_summary = {
            'totalInitialMargin': float(account_data.get('totalInitialMargin', 0)),
            'totalMaintMargin': float(account_data.get('totalMaintMargin', 0)),
            'totalWalletBalance': float(account_data.get('totalWalletBalance', 0)),
            'totalUnrealizedProfit': float(account_data.get('totalUnrealizedProfit', 0)),
            'totalMarginBalance': float(account_data.get('totalMarginBalance', 0)),
            'totalPositionInitialMargin': float(account_data.get('totalPositionInitialMargin', 0)),
            'totalOpenOrderInitialMargin': float(account_data.get('totalOpenOrderInitialMargin', 0)),
            'totalCrossWalletBalance': float(account_data.get('totalCrossWalletBalance', 0)),
            'totalCrossUnPnl': float(account_data.get('totalCrossUnPnl', 0)),
            'availableBalance': float(account_data.get('availableBalance', 0)),
            'maxWithdrawAmount': float(account_data.get('maxWithdrawAmount', 0))
        }
        
        # 4. ä»account_dataä¸­æå–assetsæ•°ç»„ï¼ˆä¸åŒ…å«positionsï¼‰
        asset_list = []
        assets = account_data.get('assets', [])
        if isinstance(assets, list):
            for asset_item in assets:
                # æå–æ¯ä¸ªèµ„äº§çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæ³¨æ„ï¼šSDKè¿”å›çš„å­—æ®µåå¯èƒ½æ˜¯é©¼å³°å‘½åï¼‰
                asset_info = {
                    'asset': asset_item.get('asset', ''),
                    'walletBalance': float(asset_item.get('walletBalance', 0)),
                    'unrealizedProfit': float(asset_item.get('unrealizedProfit', 0)),
                    'marginBalance': float(asset_item.get('marginBalance', 0)),
                    'maintMargin': float(asset_item.get('maintMargin', 0)),
                    'initialMargin': float(asset_item.get('initialMargin', 0)),
                    'positionInitialMargin': float(asset_item.get('positionInitialMargin', 0)),
                    'openOrderInitialMargin': float(asset_item.get('openOrderInitialMargin', 0)),
                    'crossWalletBalance': float(asset_item.get('crossWalletBalance', 0)),
                    'crossUnPnl': float(asset_item.get('crossUnPnl', 0)),
                    'availableBalance': float(asset_item.get('availableBalance', 0)),
                    'maxWithdrawAmount': float(asset_item.get('maxWithdrawAmount', 0))
                }
                asset_list.append(asset_info)
        
        # 5. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆaccount_aliasç”±æ•°æ®åº“æ–¹æ³•è‡ªåŠ¨ç”Ÿæˆï¼‰
        account_db = AccountDatabase(auto_init_tables=False)
        account_alias = account_db.add_account(
            account_name=account_name,
            api_key=api_key,
            api_secret=api_secret,
            account_asset_data=account_asset_summary,
            asset_list=asset_list
        )
        
        logger.info(f"Account added successfully: account_alias={account_alias}")
        return jsonify({
            'account_alias': account_alias,
            'message': 'Account added successfully'
        })
    except Exception as e:
        logger.error(f"Failed to add account: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500

@app.route('/api/accounts/<account_alias>', methods=['DELETE', 'OPTIONS'])
def delete_account(account_alias):
    """
    åˆ é™¤è´¦æˆ·
    
    Args:
        account_alias (str): è´¦æˆ·åˆ«åï¼ˆè´¦æˆ·å”¯ä¸€æ ‡è¯†ï¼‰
    
    Returns:
        JSON: åˆ é™¤æ“ä½œç»“æœ
    """
    # å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Methods', 'DELETE, OPTIONS')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        return response
    
    try:
        account_db = AccountDatabase(auto_init_tables=False)
        account_db.delete_account(account_alias)
        logger.info(f"Account {account_alias} deleted successfully")
        return jsonify({'success': True, 'message': 'Account deleted successfully'})
    except Exception as e:
        logger.error(f"Failed to delete account {account_alias}: {e}", exc_info=True)
        return jsonify({'success': False, 'error': str(e)}), 500

# ============ Main Entry Point ============

if __name__ == '__main__':
    logger.info("\n" + "=" * 60)
    logger.info("AIFutureTrade Backend Service - Starting...")
    logger.info("=" * 60)
    logger.info("Initializing database...")

    # Initialize database and trading engines within application context
    with app.app_context():
        db.init_db()
        logger.info("Database initialized")
        logger.info("Initializing trading engines...")
        init_trading_engines()
        logger.info("Trading engines initialized")

    # Start background threads
    if auto_trading:
        trading_thread = threading.Thread(target=trading_loop, daemon=True)
        trading_thread.start()
        logger.info("Auto-trading enabled")

    # Start leaderboard workers
    logger.info("ğŸš€ å‡†å¤‡å¯åŠ¨æ¶¨è·Œå¹…æ¦œç›¸å…³å·¥ä½œçº¿ç¨‹...")
    
    # å¯åŠ¨å‰ç«¯æ¨é€å·¥ä½œçº¿ç¨‹
    logger.info("ğŸ“¡ å¯åŠ¨æ¶¨è·Œå¹…æ¦œå‰ç«¯æ¨é€çº¿ç¨‹...")
    start_leaderboard_worker()
    logger.info("âœ… æ¶¨è·Œå¹…æ¦œå‰ç«¯æ¨é€çº¿ç¨‹å·²å¯åŠ¨")
    
    # åˆå§‹åŒ–åå°æœåŠ¡ï¼ˆåŒ…æ‹¬MySQLæ¶¨è·Œå¹…æ¦œåŒæ­¥çº¿ç¨‹ï¼‰
    logger.info("ğŸ“Š åˆå§‹åŒ–åå°æœåŠ¡...")
    _init_background_services()
    
    logger.info("âœ… æ‰€æœ‰æ¶¨è·Œå¹…æ¦œç›¸å…³å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨å®Œæˆ")

    logger.info("\n" + "=" * 60)
    logger.info("AIFutureTrade Backend Service is running!")
    logger.info("API Server: http://0.0.0.0:5002")
    logger.info("WebSocket Server: ws://0.0.0.0:5002")
    logger.info("=" * 60 + "\n")

    # å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨WerkzeugæœåŠ¡å™¨
    # ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨gunicorn + eventletï¼ˆè§Dockerfileå’Œgunicorn_config.pyï¼‰
    # é€šè¿‡ç¯å¢ƒå˜é‡USE_GUNICORN=trueæ¥ä½¿ç”¨gunicornå¯åŠ¨
    if os.getenv('USE_GUNICORN') == 'true':
        logger.info("Production mode: Use 'gunicorn --config gunicorn_config.py app:app' to start")
        # ç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨gunicornå¯åŠ¨ï¼Œè¿™é‡Œåªæ˜¯æç¤º
        socketio.run(
            app, 
            debug=False, 
            host='0.0.0.0', 
            port=5002, 
            use_reloader=False,
            allow_unsafe_werkzeug=True
        )
    else:
        # å¼€å‘ç¯å¢ƒ
        socketio.run(
            app, 
            debug=False, 
            host='0.0.0.0', 
            port=5002, 
            use_reloader=False,
            allow_unsafe_werkzeug=True
        )
