import sys
import os
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from market.market_data import MarketDataFetcher
from common.database_basic import Database

def estimate_tokens(data):
    """
    ä¼°ç®—JSONæ•°æ®çš„tokenæ•°é‡
    ä½¿ç”¨ç®€å•æ–¹æ³•ï¼šå­—ç¬¦æ•° / 4ï¼ˆç²—ç•¥ä¼°ç®—ï¼Œå®é™…tokenæ•°é‡å¯èƒ½å› æ¨¡å‹è€Œå¼‚ï¼‰
    æ›´å‡†ç¡®çš„æ–¹æ³•å¯ä»¥ä½¿ç”¨tiktokenåº“ï¼Œä½†è¿™é‡Œä½¿ç”¨ç®€å•ä¼°ç®—
    """
    json_str = json.dumps(data, ensure_ascii=False, default=str)
    # ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼ˆå¯¹äºè‹±æ–‡å’Œæ•°å­—ï¼‰
    # å¯¹äºä¸­æ–‡ï¼Œå¯èƒ½éœ€è¦æ›´å¤štokenï¼Œè¿™é‡Œä½¿ç”¨ä¿å®ˆä¼°ç®—
    char_count = len(json_str)
    # ä½¿ç”¨æ›´ä¿å®ˆçš„ä¼°ç®—ï¼š1 token â‰ˆ 3.5 å­—ç¬¦ï¼ˆè€ƒè™‘ä¸­æ–‡å­—ç¬¦å’Œæ ‡ç‚¹ï¼‰
    estimated_tokens = int(char_count / 3.5)
    return estimated_tokens, char_count, json_str

def test_market_data_methods():
    """æµ‹è¯•7ä¸ªæ—¶é—´å‘¨æœŸçš„å¸‚åœºæ•°æ®è·å–æ–¹æ³•ï¼Œå¹¶è®¡ç®—tokenæ•°é‡"""
    # åˆå§‹åŒ–æ•°æ®åº“å’Œå¸‚åœºæ•°æ®è·å–å™¨
    db = Database()
    db.init_db()  # åˆå§‹åŒ–æ•°æ®åº“è¡¨
    market_data = MarketDataFetcher(db)
    
    # æµ‹è¯•çš„äº¤æ˜“å¯¹
    symbol = "BTC"
    
    # æµ‹è¯•7ä¸ªæ—¶é—´å‘¨æœŸçš„æ–¹æ³•
    methods = [
        ("1m", market_data.get_market_data_1m),
        ("5m", market_data.get_market_data_5m),
        ("15m", market_data.get_market_data_15m),
        ("1h", market_data.get_market_data_1h),
        ("4h", market_data.get_market_data_4h),
        ("1d", market_data.get_market_data_1d),
        ("1w", market_data.get_market_data_1w)
    ]
    
    # å­˜å‚¨æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„æ•°æ®ç”¨äºtokenè®¡ç®—
    all_interval_data = {}
    interval_stats = {}
    
    print(f"\n{'='*80}")
    print(f"æµ‹è¯• {symbol} çš„7ä¸ªæ—¶é—´å‘¨æœŸå¸‚åœºæ•°æ®")
    print(f"{'='*80}\n")
    
    for interval, method in methods:
        print(f"\n===== æµ‹è¯• {interval} æ—¶é—´å‘¨æœŸ ====")
        
        try:
            # è°ƒç”¨æ–¹æ³•è·å–æ•°æ®
            data = method(symbol)
            
            if data:
                print(f"âœ“ æˆåŠŸè·å– {interval} æ•°æ®")
                
                # è®¡ç®—tokenæ•°é‡
                tokens, char_count, json_str = estimate_tokens(data)
                
                # ç»Ÿè®¡Kçº¿æ•°é‡
                kline_count = len(data.get('klines', []))
                
                # ç»Ÿè®¡æŒ‡æ ‡æ•°ç»„é•¿åº¦
                indicators = data.get('indicators', {})
                ma5_length = len(indicators.get('MA', {}).get('MA5', [])) if indicators.get('MA') else 0
                
                # å­˜å‚¨æ•°æ®ç”¨äºåç»­ç»Ÿè®¡
                all_interval_data[interval] = data
                interval_stats[interval] = {
                    'tokens': tokens,
                    'char_count': char_count,
                    'kline_count': kline_count,
                    'ma5_length': ma5_length
                }
                
                print(f"  Kçº¿æ•°é‡: {kline_count}")
                print(f"  MA5æ•°ç»„é•¿åº¦: {ma5_length}")
                print(f"  å­—ç¬¦æ•°: {char_count:,}")
                print(f"  ä¼°ç®—Tokenæ•°: {tokens:,}")
                print("=" * 80)
                # æ‰“å°æ•´ä½“æ•°æ®ï¼ˆJSONæ ¼å¼ï¼Œä¾¿äºæŸ¥çœ‹å®Œæ•´æ•°æ®ç»“æ„ï¼‰
                print(json.dumps(data, indent=2, ensure_ascii=False, default=str))
                print("=" * 80)
            else:
                print(f"âœ— è·å– {interval} æ•°æ®å¤±è´¥ï¼ˆè¿”å›å€¼ä¸ºç©ºï¼‰")
                interval_stats[interval] = {
                    'tokens': 0,
                    'char_count': 0,
                    'kline_count': 0,
                    'ma5_length': 0
                }
                
        except Exception as e:
            print(f"âœ— è°ƒç”¨ {interval} æ–¹æ³•å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            interval_stats[interval] = {
                'tokens': 0,
                'char_count': 0,
                'kline_count': 0,
                'ma5_length': 0
            }
    
    # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*80}")
    print(f"{symbol} æ‰€æœ‰æ—¶é—´å‘¨æœŸæ•°æ®ç»Ÿè®¡æ±‡æ€»")
    print(f"{'='*80}\n")
    
    total_tokens = 0
    total_char_count = 0
    total_kline_count = 0
    
    print(f"{'æ—¶é—´å‘¨æœŸ':<10} {'Kçº¿æ•°é‡':<12} {'MA5é•¿åº¦':<12} {'å­—ç¬¦æ•°':<15} {'Tokenæ•°':<15}")
    print("-" * 80)
    
    for interval in ["1m", "5m", "15m", "1h", "4h", "1d", "1w"]:
        stats = interval_stats.get(interval, {})
        kline_count = stats.get('kline_count', 0)
        ma5_length = stats.get('ma5_length', 0)
        char_count = stats.get('char_count', 0)
        tokens = stats.get('tokens', 0)
        
        total_tokens += tokens
        total_char_count += char_count
        total_kline_count += kline_count
        
        print(f"{interval:<10} {kline_count:<12} {ma5_length:<12} {char_count:<15,} {tokens:<15,}")
    
    print("-" * 80)
    print(f"{'æ€»è®¡':<10} {total_kline_count:<12} {'-':<12} {total_char_count:<15,} {total_tokens:<15,}")
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {symbol} ä¸€æ¬¡æäº¤7ä¸ªæ—¶é—´å‘¨æœŸæŒ‡æ ‡æ•°æ®éœ€è¦çš„Tokenæ•°é‡: {total_tokens:,}")
    print(f"   æ€»å­—ç¬¦æ•°: {total_char_count:,}")
    print(f"   æ€»Kçº¿æ•°é‡: {total_kline_count:,}")
    print(f"{'='*80}\n")
    
    # å¦‚æœæ‰€æœ‰æ•°æ®éƒ½æˆåŠŸè·å–ï¼Œè®¡ç®—åˆå¹¶åçš„tokenæ•°é‡ï¼ˆæ¨¡æ‹Ÿå®é™…æäº¤æ ¼å¼ï¼‰
    if all_interval_data:
        print(f"\n{'='*80}")
        print(f"æ¨¡æ‹Ÿå®é™…æäº¤æ ¼å¼ï¼ˆåˆå¹¶æ‰€æœ‰æ—¶é—´å‘¨æœŸæ•°æ®ï¼‰")
        print(f"{'='*80}\n")
        
        # æ„å»ºåˆå¹¶æ•°æ®æ ¼å¼ï¼ˆæ¨¡æ‹Ÿå®é™…æäº¤ç»™æ¨¡å‹çš„æ•°æ®ç»“æ„ï¼‰
        merged_data = {
            'symbol': symbol,
            'timeframes': all_interval_data
        }
        
        merged_tokens, merged_char_count, _ = estimate_tokens(merged_data)
        
        print(f"åˆå¹¶åæ•°æ®ç»Ÿè®¡:")
        print(f"  å­—ç¬¦æ•°: {merged_char_count:,}")
        print(f"  ä¼°ç®—Tokenæ•°: {merged_tokens:,}")
        print(f"\næ³¨æ„: å®é™…æäº¤æ—¶å¯èƒ½è¿˜éœ€è¦é¢å¤–çš„promptæ–‡æœ¬ï¼Œå®é™…tokenæ¶ˆè€—å¯èƒ½æ›´é«˜")
        print(f"{'='*80}\n")

if __name__ == "__main__":
    test_market_data_methods()